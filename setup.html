<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Setup Guide - Live Transcript</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background-color: white;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #1a73e8;
            border-bottom: 2px solid #1a73e8;
            padding-bottom: 10px;
        }
        h2 {
            color: #333;
            margin-top: 30px;
        }
        p {
            color: #555;
            margin-bottom: 15px;
        }
        ul, ol {
            color: #555;
        }
        .step {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 5px;
            margin: 20px 0;
            border-left: 4px solid #1a73e8;
        }
        .requirement {
            background-color: #e8f5e8;
            padding: 15px;
            border-radius: 5px;
            margin: 20px 0;
        }
        .warning {
            background-color: #fff3cd;
            padding: 15px;
            border-radius: 5px;
            border-left: 4px solid #ffc107;
            margin: 20px 0;
        }
        .code {
            background-color: #f8f9fa;
            padding: 10px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            border: 1px solid #dee2e6;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Live Transcript Setup Guide</h1>
        <p>Welcome to Live Transcript! This guide will help you set up and start using real-time transcription in your Google Meet sessions.</p>
        
        <div class="requirement">
            <h2>üìã Requirements</h2>
            <ul>
                <li><strong>Google Workspace Account:</strong> You need a Google Workspace account with Google Meet access</li>
                <li><strong>Modern Web Browser:</strong> Chrome, Firefox, Safari, or Edge (latest versions)</li>
                <li><strong>Microphone Access:</strong> Your browser must have permission to access your microphone</li>
                <li><strong>Stable Internet Connection:</strong> For real-time audio processing</li>
            </ul>
        </div>
        
        <h2>üöÄ Installation Steps</h2>
        
        <div class="step">
            <h3>Step 1: Install from Google Workspace Marketplace</h3>
            <ol>
                <li>Go to the <a href="https://workspace.google.com/marketplace" target="_blank">Google Workspace Marketplace</a></li>
                <li>Search for "Live Transcript"</li>
                <li>Click on the Live Transcript listing</li>
                <li>Click "Install" and follow the prompts</li>
                <li>Grant the necessary permissions when prompted</li>
            </ol>
        </div>
        
        <div class="step">
            <h3>Step 2: Grant Permissions</h3>
            <p>When installing, you'll be asked to grant the following permissions:</p>
            <ul>
                <li><strong>Meeting Access:</strong> To access Google Meet sessions</li>
                <li><strong>Audio Access:</strong> To capture audio for transcription</li>
                <li><strong>Participant Information:</strong> To identify speakers</li>
            </ul>
            <p>Click "Allow" to grant these permissions.</p>
        </div>
        
        <div class="step">
            <h3>Step 3: Start a Google Meet Session</h3>
            <ol>
                <li>Open Google Meet in your browser</li>
                <li>Start a new meeting or join an existing one</li>
                <li>Ensure your microphone is working properly</li>
                <li>Wait for the meeting to load completely</li>
            </ol>
        </div>
        
        <div class="step">
            <h3>Step 4: Access Live Transcript</h3>
            <ol>
                <li>Look for the Live Transcript icon in the Google Meet interface</li>
                <li>Click on the Live Transcript icon</li>
                <li>You'll see the add-on panel open on the right side</li>
                <li>Click "Start Activity" to begin transcription</li>
            </ol>
        </div>
        
        <div class="step">
            <h3>Step 5: Start Transcription</h3>
            <ol>
                <li>In the Live Transcript panel, click "Start Live Transcript"</li>
                <li>Grant microphone permissions if prompted by your browser</li>
                <li>Wait for the transcription to begin</li>
                <li>You'll see real-time text appearing as participants speak</li>
            </ol>
        </div>
        
        <h2>üéØ Using Live Transcript</h2>
        
        <h3>Side Panel Controls</h3>
        <ul>
            <li><strong>Start/Stop Transcription:</strong> Toggle transcription on and off</li>
            <li><strong>Participant List:</strong> View all meeting participants</li>
            <li><strong>Settings:</strong> Adjust transcription preferences</li>
        </ul>
        
        <h3>Main Stage View</h3>
        <ul>
            <li><strong>Full-Screen Transcript:</strong> Click "Start Activity" to open the main transcript view</li>
            <li><strong>Speaker Identification:</strong> See who is speaking with each transcript line</li>
            <li><strong>Real-Time Updates:</strong> Watch transcripts appear as participants speak</li>
        </ul>
        
        <div class="warning">
            <h3>‚ö†Ô∏è Important Notes</h3>
            <ul>
                <li><strong>Participant Consent:</strong> All meeting participants should be aware that transcription is active</li>
                <li><strong>Audio Quality:</strong> Clear audio input results in better transcription accuracy</li>
                <li><strong>Internet Connection:</strong> Stable connection is required for real-time processing</li>
                <li><strong>Browser Permissions:</strong> Ensure your browser allows microphone access</li>
            </ul>
        </div>
        
        <h2>üîß Troubleshooting</h2>
        
        <h3>Common Issues</h3>
        
        <div class="code">
            <strong>Issue:</strong> Add-on icon not appearing in Google Meet<br>
            <strong>Solution:</strong> Refresh the page and ensure the add-on is properly installed
        </div>
        
        <div class="code">
            <strong>Issue:</strong> No audio being captured<br>
            <strong>Solution:</strong> Check browser microphone permissions and ensure microphone is not muted
        </div>
        
        <div class="code">
            <strong>Issue:</strong> Transcription not starting<br>
            <strong>Solution:</strong> Verify internet connection and try refreshing the page
        </div>
        
        <h3>Browser-Specific Instructions</h3>
        
        <h4>Chrome</h4>
        <ol>
            <li>Click the lock icon in the address bar</li>
            <li>Ensure "Microphone" is set to "Allow"</li>
            <li>Refresh the page if needed</li>
        </ol>
        
        <h4>Firefox</h4>
        <ol>
            <li>Click the shield icon in the address bar</li>
            <li>Click "Permissions" and ensure microphone access is allowed</li>
            <li>Refresh the page if needed</li>
        </ol>
        
        <h4>Safari</h4>
        <ol>
            <li>Go to Safari > Preferences > Websites</li>
            <li>Select "Microphone" and ensure it's set to "Allow"</li>
            <li>Refresh the page if needed</li>
        </ol>
        
        <h2>üìû Getting Help</h2>
        <p>If you encounter any issues during setup or use:</p>
        <ul>
            <li>Check our <a href="help.html">Help & FAQ</a> page</li>
            <li>Visit our <a href="support.html">Support</a> page</li>
            <li>Report issues on <a href="https://github.com/SuduguTejasvi/meet-transcript-addon/issues" target="_blank">GitHub</a></li>
            <li>Contact us at <a href="mailto:support@meet-transcript.com">support@meet-transcript.com</a></li>
        </ul>
        
        <div class="requirement">
            <h2>‚úÖ Setup Complete!</h2>
            <p>Once you've completed these steps, you should be able to use Live Transcript in your Google Meet sessions. Enjoy real-time transcription!</p>
        </div>

        <div class="step">
            <h3>Optional: Browser Audio Capture (no Meet API)</h3>
            <p>Capture audio directly in your browser without the Google Meet API. You can stream from your microphone or from the current tab (share tab audio) and get real‚Äëtime transcripts.</p>
            <div style="margin:12px 0;">
                <label><strong>Deepgram API Key</strong></label><br>
                <input id="dgKey" type="password" placeholder="dg_xxx..." style="width:100%;max-width:520px;">
            </div>
            <div style="margin:12px 0; display:flex; gap:8px; flex-wrap:wrap;">
                <button id="startMic">Start Mic Transcription</button>
                <button id="startTab">Start Current Tab Transcription</button>
                <button id="stopAll" disabled>Stop</button>
            </div>
            <pre id="dgLog" class="code" style="height:260px; overflow:auto; white-space:pre-wrap;"></pre>
            <div id="dgOut" class="code" style="margin-top:10px; min-height:60px;"></div>
            <p style="font-size:12px;color:#666; margin-top:8px;">Note: For tab audio, your browser will prompt you to "Share this tab" and you must enable "Share tab audio". This captures audio locally in your browser and does not join the meeting as a bot.</p>
        </div>
    </div>
</body>
<script>
(function() {
    const logEl = document.getElementById('dgLog');
    const outEl = document.getElementById('dgOut');
    const startMicBtn = document.getElementById('startMic');
    const startTabBtn = document.getElementById('startTab');
    const stopBtn = document.getElementById('stopAll');
    const keyEl = document.getElementById('dgKey');

    let ws = null;
    let audioContext = null;
    let mediaStream = null;
    let processor = null;
    let sourceNode = null;

    function log() {
        const msg = Array.from(arguments).join(' ');
        logEl.textContent += msg + '\n';
        logEl.scrollTop = logEl.scrollHeight;
    }

    function floatTo16BitPCM(float32Array) {
        const int16 = new Int16Array(float32Array.length);
        for (let i = 0; i < float32Array.length; i++) {
            const s = Math.max(-1, Math.min(1, float32Array[i]));
            int16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
        }
        return int16;
    }

    function openDeepgram(key) {
        return new Promise((resolve, reject) => {
            const url = 'wss://api.deepgram.com/v1/listen?model=nova-2&language=en-US&punctuate=true&diarize=true&interim_results=true&smart_format=true&encoding=linear16&sample_rate=16000&channels=1';
            ws = new WebSocket(url, []);
            // Deepgram expects the key in the Authorization header; browsers can't set headers for WS.
            // Deepgram also supports the "token" query param for browser WS.
            // If your key is a short-lived token, append as ?token=... Instead, we will send an auth message.
            ws.addEventListener('open', () => {
                try {
                    ws.send(JSON.stringify({ type: 'authorization', token: key }));
                } catch(e) {}
                resolve();
            });
            ws.addEventListener('error', (e) => reject(e));
            ws.addEventListener('close', () => log('Deepgram socket closed'));
            ws.addEventListener('message', (evt) => {
                try {
                    const data = JSON.parse(evt.data);
                    if (data.channel && data.channel.alternatives && data.channel.alternatives[0]) {
                        const alt = data.channel.alternatives[0];
                        if (alt.transcript) {
                            outEl.textContent = alt.transcript;
                        }
                    }
                } catch (_) {}
            });
        });
    }

    async function startCapture(kind) {
        const key = keyEl.value.trim();
        if (!key) { log('Please enter Deepgram API key'); return; }
        stopCapture();
        log('Opening Deepgram‚Ä¶');
        try {
            await openDeepgram(key);
        } catch (e) {
            log('Failed to connect to Deepgram:', e.message || e);
            return;
        }

        try {
            if (kind === 'mic') {
                mediaStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });
                log('Mic stream started');
            } else {
                const ds = await navigator.mediaDevices.getDisplayMedia({
                    audio: true,
                    video: true
                });
                // Prefer the audio track, we don't need to render video
                const v = ds.getVideoTracks()[0];
                if (v) v.stop();
                mediaStream = new MediaStream(ds.getAudioTracks());
                log('Tab audio stream started (ensure "Share tab audio" was enabled)');
            }
        } catch (e) {
            log('Failed to start media:', e.message || e);
            return;
        }

        try {
            // Use 16kHz context for direct linear16 streaming
            audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
            sourceNode = audioContext.createMediaStreamSource(mediaStream);
            processor = audioContext.createScriptProcessor(4096, 1, 1);
            processor.onaudioprocess = (evt) => {
                if (!ws || ws.readyState !== 1) return;
                const input = evt.inputBuffer.getChannelData(0);
                const int16 = floatTo16BitPCM(input);
                ws.send(int16);
            };
            sourceNode.connect(processor);
            processor.connect(audioContext.destination);
            stopBtn.disabled = false;
            startMicBtn.disabled = true;
            startTabBtn.disabled = true;
            log('Streaming audio to Deepgram‚Ä¶');
        } catch (e) {
            log('Audio pipeline error:', e.message || e);
            stopCapture();
        }
    }

    function stopCapture() {
        try { if (processor) processor.disconnect(); } catch(_) {}
        try { if (sourceNode) sourceNode.disconnect(); } catch(_) {}
        try { if (audioContext) audioContext.close(); } catch(_) {}
        processor = null; sourceNode = null; audioContext = null;
        if (mediaStream) {
            mediaStream.getTracks().forEach(t => { try { t.stop(); } catch(_) {} });
            mediaStream = null;
        }
        if (ws) {
            try { ws.close(); } catch(_) {}
            ws = null;
        }
        stopBtn.disabled = true;
        startMicBtn.disabled = false;
        startTabBtn.disabled = false;
    }

    startMicBtn.addEventListener('click', () => startCapture('mic'));
    startTabBtn.addEventListener('click', () => startCapture('tab'));
    stopBtn.addEventListener('click', () => { log('Stopping‚Ä¶'); stopCapture(); });
})();
</script>
</html>
