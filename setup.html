<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Setup Guide - Live Transcript</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background-color: white;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #1a73e8;
            border-bottom: 2px solid #1a73e8;
            padding-bottom: 10px;
        }
        h2 {
            color: #333;
            margin-top: 30px;
        }
        p {
            color: #555;
            margin-bottom: 15px;
        }
        ul, ol {
            color: #555;
        }
        .step {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 5px;
            margin: 20px 0;
            border-left: 4px solid #1a73e8;
        }
        .requirement {
            background-color: #e8f5e8;
            padding: 15px;
            border-radius: 5px;
            margin: 20px 0;
        }
        .warning {
            background-color: #fff3cd;
            padding: 15px;
            border-radius: 5px;
            border-left: 4px solid #ffc107;
            margin: 20px 0;
        }
        .code {
            background-color: #f8f9fa;
            padding: 10px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            border: 1px solid #dee2e6;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Live Transcript Setup Guide</h1>
        <p>Welcome to Live Transcript! This guide will help you set up and start using real-time transcription in your Google Meet sessions.</p>

        <div class="step">
            <h3>Optional: Browser-based audio capture (no Meet API)</h3>
            <p>
                You can capture audio directly in the browser from your microphone or the current tab (e.g., Google Meet tab)
                and stream it to the transcription service without joining as a bot. This preserves meeting quality and user experience.
            </p>
            <div style="display: grid; gap: 10px; margin-top: 10px;">
                <label for="dg-key"><strong>Deepgram API Key</strong></label>
                <input id="dg-key" type="password" placeholder="dg_xxx..." style="padding: 8px; width: 100%;" />

                <div style="display:flex; gap:8px; flex-wrap: wrap; margin-top: 6px;">
                    <button id="start-tab" style="padding:10px 14px; background:#34a853; color:#fff; border:none; border-radius:6px; cursor:pointer;">Start Tab Transcript</button>
                    <button id="start-mic" style="padding:10px 14px; background:#1a73e8; color:#fff; border:none; border-radius:6px; cursor:pointer;">Start Mic Transcript</button>
                    <button id="stop-cap" style="padding:10px 14px; background:#ea4335; color:#fff; border:none; border-radius:6px; cursor:not-allowed; opacity:.6;" disabled>Stop</button>
                </div>

                <div id="cap-status" class="code" style="display:none;">Ready</div>
                <pre id="cap-log" class="code" style="height: 240px; overflow:auto; white-space: pre-wrap;"></pre>
            </div>
        </div>
        
        <div class="requirement">
            <h2>üìã Requirements</h2>
            <ul>
                <li><strong>Google Workspace Account:</strong> You need a Google Workspace account with Google Meet access</li>
                <li><strong>Modern Web Browser:</strong> Chrome, Firefox, Safari, or Edge (latest versions)</li>
                <li><strong>Microphone Access:</strong> Your browser must have permission to access your microphone</li>
                <li><strong>Stable Internet Connection:</strong> For real-time audio processing</li>
            </ul>
        </div>
        
        <h2>üöÄ Installation Steps</h2>
        
        <div class="step">
            <h3>Step 1: Install from Google Workspace Marketplace</h3>
            <ol>
                <li>Go to the <a href="https://workspace.google.com/marketplace" target="_blank">Google Workspace Marketplace</a></li>
                <li>Search for "Live Transcript"</li>
                <li>Click on the Live Transcript listing</li>
                <li>Click "Install" and follow the prompts</li>
                <li>Grant the necessary permissions when prompted</li>
            </ol>
        </div>
        
        <div class="step">
            <h3>Step 2: Grant Permissions</h3>
            <p>When installing, you'll be asked to grant the following permissions:</p>
            <ul>
                <li><strong>Meeting Access:</strong> To access Google Meet sessions</li>
                <li><strong>Audio Access:</strong> To capture audio for transcription</li>
                <li><strong>Participant Information:</strong> To identify speakers</li>
            </ul>
            <p>Click "Allow" to grant these permissions.</p>
        </div>
        
        <div class="step">
            <h3>Step 3: Start a Google Meet Session</h3>
            <ol>
                <li>Open Google Meet in your browser</li>
                <li>Start a new meeting or join an existing one</li>
                <li>Ensure your microphone is working properly</li>
                <li>Wait for the meeting to load completely</li>
            </ol>
        </div>
        
        <div class="step">
            <h3>Step 4: Access Live Transcript</h3>
            <ol>
                <li>Look for the Live Transcript icon in the Google Meet interface</li>
                <li>Click on the Live Transcript icon</li>
                <li>You'll see the add-on panel open on the right side</li>
                <li>Click "Start Activity" to begin transcription</li>
            </ol>
        </div>
        
        <div class="step">
            <h3>Step 5: Start Transcription</h3>
            <ol>
                <li>In the Live Transcript panel, click "Start Live Transcript"</li>
                <li>Grant microphone permissions if prompted by your browser</li>
                <li>Wait for the transcription to begin</li>
                <li>You'll see real-time text appearing as participants speak</li>
            </ol>
        </div>
        
        <h2>üéØ Using Live Transcript</h2>
        
        <h3>Side Panel Controls</h3>
        <ul>
            <li><strong>Start/Stop Transcription:</strong> Toggle transcription on and off</li>
            <li><strong>Participant List:</strong> View all meeting participants</li>
            <li><strong>Settings:</strong> Adjust transcription preferences</li>
        </ul>
        
        <h3>Main Stage View</h3>
        <ul>
            <li><strong>Full-Screen Transcript:</strong> Click "Start Activity" to open the main transcript view</li>
            <li><strong>Speaker Identification:</strong> See who is speaking with each transcript line</li>
            <li><strong>Real-Time Updates:</strong> Watch transcripts appear as participants speak</li>
        </ul>
        
        <div class="warning">
            <h3>‚ö†Ô∏è Important Notes</h3>
            <ul>
                <li><strong>Participant Consent:</strong> All meeting participants should be aware that transcription is active</li>
                <li><strong>Audio Quality:</strong> Clear audio input results in better transcription accuracy</li>
                <li><strong>Internet Connection:</strong> Stable connection is required for real-time processing</li>
                <li><strong>Browser Permissions:</strong> Ensure your browser allows microphone access</li>
            </ul>
        </div>
        
        <h2>üîß Troubleshooting</h2>
        
        <h3>Common Issues</h3>
        
        <div class="code">
            <strong>Issue:</strong> Add-on icon not appearing in Google Meet<br>
            <strong>Solution:</strong> Refresh the page and ensure the add-on is properly installed
        </div>
        
        <div class="code">
            <strong>Issue:</strong> No audio being captured<br>
            <strong>Solution:</strong> Check browser microphone permissions and ensure microphone is not muted
        </div>
        
        <div class="code">
            <strong>Issue:</strong> Transcription not starting<br>
            <strong>Solution:</strong> Verify internet connection and try refreshing the page
        </div>
        
        <h3>Browser-Specific Instructions</h3>
        
        <h4>Chrome</h4>
        <ol>
            <li>Click the lock icon in the address bar</li>
            <li>Ensure "Microphone" is set to "Allow"</li>
            <li>Refresh the page if needed</li>
        </ol>
        
        <h4>Firefox</h4>
        <ol>
            <li>Click the shield icon in the address bar</li>
            <li>Click "Permissions" and ensure microphone access is allowed</li>
            <li>Refresh the page if needed</li>
        </ol>
        
        <h4>Safari</h4>
        <ol>
            <li>Go to Safari > Preferences > Websites</li>
            <li>Select "Microphone" and ensure it's set to "Allow"</li>
            <li>Refresh the page if needed</li>
        </ol>
        
        <h2>üìû Getting Help</h2>
        <p>If you encounter any issues during setup or use:</p>
        <ul>
            <li>Check our <a href="help.html">Help & FAQ</a> page</li>
            <li>Visit our <a href="support.html">Support</a> page</li>
            <li>Report issues on <a href="https://github.com/SuduguTejasvi/meet-transcript-addon/issues" target="_blank">GitHub</a></li>
            <li>Contact us at <a href="mailto:support@meet-transcript.com">support@meet-transcript.com</a></li>
        </ul>
        
        <div class="requirement">
            <h2>‚úÖ Setup Complete!</h2>
            <p>Once you've completed these steps, you should be able to use Live Transcript in your Google Meet sessions. Enjoy real-time transcription!</p>
        </div>
    </div>

    <script>
        (function() {
            const startTabBtn = document.getElementById('start-tab');
            const startMicBtn = document.getElementById('start-mic');
            const stopBtn = document.getElementById('stop-cap');
            const statusEl = document.getElementById('cap-status');
            const logEl = document.getElementById('cap-log');
            const keyEl = document.getElementById('dg-key');

            let ws = null;
            let audioContext = null;
            let sourceNode = null;
            let processorNode = null;
            let activeStream = null;

            function log() {
                logEl.textContent += Array.from(arguments).join(' ') + '\n';
                logEl.scrollTop = logEl.scrollHeight;
            }

            function setStatus(text, type = 'info') {
                statusEl.style.display = 'block';
                statusEl.style.background = type === 'error' ? '#fce8e6' : type === 'ok' ? '#e8f5e8' : '#e8f0fe';
                statusEl.style.color = type === 'error' ? '#d93025' : type === 'ok' ? '#137333' : '#1a73e8';
                statusEl.textContent = text;
            }

            function enableControls(running) {
                startTabBtn.disabled = running;
                startMicBtn.disabled = running;
                stopBtn.disabled = !running;
                stopBtn.style.opacity = running ? '1' : '.6';
                stopBtn.style.cursor = running ? 'pointer' : 'not-allowed';
            }

            function connectDeepgram(apiKey) {
                return new Promise((resolve, reject) => {
                    try {
                        const base = 'wss://api.deepgram.com/v1/listen';
                        const params = new URLSearchParams({
                            model: 'nova-2',
                            language: 'en-US',
                            punctuate: 'true',
                            interim_results: 'true',
                            smart_format: 'true',
                            encoding: 'linear16',
                            sample_rate: '16000',
                            channels: '1',
                            token: apiKey
                        });
                        const url = `${base}?${params.toString()}`;
                        ws = new WebSocket(url);
                        ws.onopen = () => { log('Deepgram connected'); resolve(); };
                        ws.onerror = (e) => { reject(new Error('WebSocket error')); };
                        ws.onclose = () => { log('Deepgram closed'); };
                        ws.onmessage = (evt) => {
                            try {
                                const msg = JSON.parse(evt.data);
                                const alt = msg?.channel?.alternatives?.[0];
                                if (alt && alt.transcript) {
                                    const prefix = msg.is_final ? 'FINAL' : 'PART';
                                    log(`[${prefix}]`, alt.transcript);
                                }
                            } catch (_) { /* ignore non-JSON */ }
                        };
                    } catch (err) {
                        reject(err);
                    }
                });
            }

            function startProcessing(stream) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                sourceNode = audioContext.createMediaStreamSource(stream);
                processorNode = audioContext.createScriptProcessor(4096, 1, 1);
                processorNode.onaudioprocess = (e) => {
                    if (!ws || ws.readyState !== WebSocket.OPEN) return;
                    const input = e.inputBuffer.getChannelData(0);
                    const int16 = new Int16Array(input.length);
                    for (let i = 0; i < input.length; i++) {
                        let s = Math.max(-1, Math.min(1, input[i]));
                        int16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                    }
                    ws.send(int16);
                };
                sourceNode.connect(processorNode);
                processorNode.connect(audioContext.destination);
                activeStream = stream;
            }

            async function startTabCapture() {
                const key = (keyEl.value || '').trim();
                if (!key) { setStatus('Enter Deepgram API key', 'error'); return; }
                enableControls(true);
                try {
                    setStatus('Requesting tab audio‚Ä¶');
                    const stream = await navigator.mediaDevices.getDisplayMedia({ audio: { echoCancellation: true }, video: true });
                    // Some browsers may separate system audio; ensure at least one audio track exists
                    if (!stream.getAudioTracks().length) {
                        throw new Error('No audio track in captured tab');
                    }
                    await connectDeepgram(key);
                    startProcessing(stream);
                    setStatus('Transcribing tab audio‚Ä¶', 'ok');
                } catch (e) {
                    log('Start tab error:', e.message || e);
                    setStatus(e.message || 'Failed to start tab capture', 'error');
                    enableControls(false);
                }
            }

            async function startMicCapture() {
                const key = (keyEl.value || '').trim();
                if (!key) { setStatus('Enter Deepgram API key', 'error'); return; }
                enableControls(true);
                try {
                    setStatus('Requesting microphone‚Ä¶');
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: { echoCancellation: true, noiseSuppression: true }, video: false });
                    await connectDeepgram(key);
                    startProcessing(stream);
                    setStatus('Transcribing microphone‚Ä¶', 'ok');
                } catch (e) {
                    log('Start mic error:', e.message || e);
                    setStatus(e.message || 'Failed to start mic capture', 'error');
                    enableControls(false);
                }
            }

            function stopAll() {
                try { if (processorNode) processorNode.disconnect(); } catch (_) {}
                try { if (sourceNode) sourceNode.disconnect(); } catch (_) {}
                try { if (audioContext) audioContext.close(); } catch (_) {}
                processorNode = null; sourceNode = null; audioContext = null;
                if (activeStream) {
                    activeStream.getTracks().forEach(t => { try { t.stop(); } catch (_) {} });
                    activeStream = null;
                }
                if (ws) { try { ws.close(); } catch (_) {} ws = null; }
                setStatus('Capture stopped');
                enableControls(false);
            }

            startTabBtn?.addEventListener('click', startTabCapture);
            startMicBtn?.addEventListener('click', startMicCapture);
            stopBtn?.addEventListener('click', stopAll);
        })();
    </script>
</body>
</html>
